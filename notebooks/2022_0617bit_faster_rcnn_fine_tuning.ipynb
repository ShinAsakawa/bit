{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/bit/blob/main/notebooks/2022_0617bit_faster_rcnn_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBJdUyBhb1J_"
      },
      "source": [
        "---\n",
        "- date: 2022_0604 original file written at 2022_0319\n",
        "- filename: 2022_0604bit_faster-rcnn_fine_tuning.ipynb\n",
        "- ref source: https://www.kaggle.com/yerramvarun/fine-tuning-faster-rcnn-using-pytorch/notebook\n",
        "---\n",
        "\n",
        "**注**: workers=0 で動作するので時間がかかる"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive からデータを入手\n",
        "# このセルを実行するとブラウザの別タブで Google アカウントへの認証が求められる\n",
        "# Google アカウントを選択するとクリデンシャルキーが表示されるので，そのキーを\n",
        "# コピーして，このセルの出力欄にある空欄に貼り付けてエンターキー (リターンキー) を押下する\n",
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# 以下実際のデータの情報\n",
        "#https://drive.google.com/file/d/1xKXbovkEQwdJefzCuaS_a351LUIuRz-1/view?usp=sharing  for  cis.twcu.ac.jp/GitHub_shared/ccap_data.tgz on Gdrive\n",
        "#https://drive.google.com/file/d/1PVwPXiBiRX4Aueqc3MHuosG5mWNnrvVa/view?usp=sharing  for 2022_0605fine_tuned_bit_line_bisection_pasiphae.cpt on Gdrive\n",
        "\n",
        "file_id = '1xKXbovkEQwdJefzCuaS_a351LUIuRz-1'\n",
        "file_id = '1PVwPXiBiRX4Aueqc3MHuosG5mWNnrvVa'\n",
        "file_id = '1W5jPu6xggW1y9oaNuF_SbKEm7ZnwmtQL'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('2022_0605fine_tuned_bit_line_bisection_pasiphae.cpt')"
      ],
      "metadata": {
        "id": "NAbMaGyAL60Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Y396uYb1KB"
      },
      "source": [
        "# faster-rcnn 転移学習または微調整を用いた BIT 線分 2 等分課題\n",
        "\n",
        "[BIT] 図版を [Faster RCNN](https://arxiv.org/abs/1506.01497) で微調整して訓練\n",
        "\n",
        "* Faster RCNNについては [Faster-RCNNの仕組みをより深く理解するために](https://medium.com/@whatdhack/a-deeper-look-how-faster-rcnn-works-84081284e1cd) の Media 参照。\n",
        "* [Pytorch 公式チュートリアル文書](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html) も参照\n",
        "\n",
        "転移学習 transfer learning と微調整 fine tuning については，種々考え方がある。\n",
        "だがここでは，[PyTorch のチュートリアル](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) に従って，\n",
        "最終層だけ入れ替えて，最終直下層以下の結合係数を固定して考える場合を転移学習と呼ぶことにする。\n",
        "全層を再学習することを，微調整と呼ぶことにする。\n",
        "このチュートリアルが参照にしているのは，Karpathy の スタンフォードでの授業 [cs231n の転移学習のノート](https://cs231n.github.io/transfer-learning/) である。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwfe8g60b1KD"
      },
      "source": [
        "# 1. インストールとインポート\n",
        "<!-- ## Installs and Imports -->\n",
        "\n",
        "## 1.1 下準備\n",
        "\n",
        "必要なライブラリのインストールなど"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2022_0605 現在，下記の再インストールが必要のようだ\n",
        "# また，訓練時に halt する\n",
        "!pip install --upgrade albumentations\n",
        "#!pip uninstall opencv-python-headless==4.5.5.62\n",
        "#!pip install opencv-python-headless==4.5.2.52\n",
        "!pip install opencv-python-headless --upgrade"
      ],
      "metadata": {
        "id": "p5S5HRKH9DY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "KMPZyEqqb1KE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import typing\n",
        "import cv2\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "if isColab:\n",
        "    from PIL import ImageFont\n",
        "    from glob import glob\n",
        "\n",
        "    !pip install pycocotools --quiet\n",
        "    !git clone https://github.com/pytorch/vision.git\n",
        "    !git checkout v0.3.0\n",
        "\n",
        "    # Download TorchVision repo to use some files from references/detection\n",
        "    # os.symlink(src,dst) にした方が良いかも\n",
        "    !cp vision/references/detection/utils.py ./\n",
        "    !cp vision/references/detection/transforms.py ./\n",
        "    !cp vision/references/detection/coco_eval.py ./\n",
        "    !cp vision/references/detection/engine.py ./\n",
        "    !cp vision/references/detection/coco_utils.py ./\n",
        "\n",
        "    !pip install japanize_matplotlib\n",
        "    #!pip install albumentataions  # 2022_0604 一時的に中断 colab でエラー発生のため\n",
        "\n",
        "    # 自作ライブラリ\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "\n",
        "    # Noto fonts のダウンロードとインストール\n",
        "    !mkdir Noto_JP_fonts\n",
        "    !wget https://noto-website-2.storage.googleapis.com/pkgs/NotoSerifJP.zip\n",
        "    !wget https://noto-website-2.storage.googleapis.com/pkgs/NotoSansJP.zip\n",
        "    !unzip NotoSerifJP.zip -d Noto_JP_fonts\n",
        "    !unzip -o NotoSansJP.zip -d Noto_JP_fonts  # `-o` means overwrite\n",
        "    !mv Noto_JP_fonts bit\n",
        "    !mkdir data\n",
        "\n",
        "    noto_font_dir = './bit/Noto_JP_fonts'\n",
        "    notofonts_fnames = glob(os.path.join(noto_font_dir,'*otf'))\n",
        "    notofonts = {fname.split('/')[-1].split('.')[0]:{'fname':fname} for fname in notofonts_fnames}\n",
        "    for fontname in notofonts.keys():\n",
        "        notofonts[fontname]['data'] = ImageFont.truetype(notofonts[fontname]['fname'])\n",
        "else:\n",
        "    # 自分のリポジトリからシンボリックリンクで代用\n",
        "    for file in ['engine.py', 'utils.py', 'coco_utils.py', 'transforms.py', 'coco_eval.py']:\n",
        "        if not os.path.exists(file):\n",
        "            _file = os.path.join('../2020pytorch_vision.git/reference/detection/', file)\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/engine.py .\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/utils.py .\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/coco_utils.py .\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/transforms.py .\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/coco_eval.py .\n",
        "\n",
        "\n",
        "# DETR のサンプルプログラムを借用\n",
        "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
        "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n",
        "COLORS = COLORS * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOWNVBjIb1KF"
      },
      "source": [
        "## 1.2 ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WhUrMEyDb1KG"
      },
      "outputs": [],
      "source": [
        "# ライブラリのインポート\n",
        "# python と機械学習のための基本ライブラリ\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import japanize_matplotlib\n",
        "\n",
        "# torchvision ライブラリ\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as torchtrans\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# ヘルパライブラリをインポート\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if isColab:\n",
        "    !pip install --upgrade ipynbname"
      ],
      "metadata": {
        "id": "w8hzdJNkU45F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwnrXEyyb1KH"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from bit import BIT\n",
        "\n",
        "if isColab:\n",
        "    bit = BIT(fontdata=notofonts)\n",
        "else:\n",
        "    bit = BIT()\n",
        "images, bboxes = bit.make_line_bisection_task_images(N=1, n_lines=3)\n",
        "\n",
        "import PIL\n",
        "def plot_pilimg_and_bbox(pil_img:PIL.Image.Image,\n",
        "                         bboxes:list,\n",
        "                         verbose:bool=False\n",
        "                        ):\n",
        "    \"\"\"bounding box (物体を囲む四角形の境界領域のことを境界領域箱と呼ぶ): bbox\n",
        "    PIL 画像を境界領域と共に表示する関数\"\"\"\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.imshow(pil_img)\n",
        "    ax = plt.gca()\n",
        "    for (xmin, ymin, xmax, ymax), c in zip(bboxes, COLORS):\n",
        "        if verbose:\n",
        "            print(f'xmin:{xmin}, ymin:{ymin}')\n",
        "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                   fill=False, color=c, linewidth=2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bit import BIT_LineBisection\n",
        "train_dataset = BIT_LineBisection(_symbols=bit.symbols, dirname='bit/data/line_bisection/train')\n",
        "test_dataset = BIT_LineBisection(_symbols=bit.symbols, dirname='bit/data/line_bisection/test')"
      ],
      "metadata": {
        "id": "IInfaydKNoFA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bit import get_object_detection_model\n",
        "\n",
        "num_classes = len(bit.symbols)\n",
        "print(f'num_classes:{num_classes}, bit.symbols:{bit.symbols}')\n",
        "model = get_object_detection_model(num_classes)"
      ],
      "metadata": {
        "id": "XYTvBV8Y2QiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XXX = torch.load('2022_0605fine_tuned_bit_line_bisection_pasiphae.cpt')\n",
        "model.load_state_dict(XXX['model'])\n",
        "#help(model)"
      ],
      "metadata": {
        "id": "D1v9Zb5hOzsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_to_pil(img):\n",
        "    \"\"\"torchtensor を PIL 画像に変換する関数\n",
        "    function to convert a torchtensor back to PIL image\"\"\"\n",
        "    return torchtrans.ToPILImage()(img).convert('RGB')\n",
        "\n",
        "# 可能なら GPU 上で学習させる\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "XP8_6VKFOX2r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bit import plot_img_bbox\n",
        "\n",
        "_dataset = test_dataset\n",
        "for N in range(_dataset.__len__()):\n",
        "    #N = np.random.choice(len(_dataset)) # テストセットから画像を 1 枚選ぶ\n",
        "    img, target = _dataset[N]\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = model([img.to(device)])[0]\n",
        "\n",
        "    plot_img_bbox(torch_to_pil(img), target, title=\"グランドトルース\")\n",
        "    plot_img_bbox(torch_to_pil(img), prediction, title=\"モデル予測\")"
      ],
      "metadata": {
        "id": "UlD42BOyOa7n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "2022_0604bit_faster-rcnn_fine_tuning.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}